{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier in TensorFlow: Binary Classification Example\n",
    "\n",
    "## What is Linear Classifier?\n",
    "\n",
    "The two most common supervised learning tasks are linear regression and linear classifier. Linear regression predicts a value while the linear classifier predicts a class. This tutorial is focused on Linear Classifier.\n",
    "\n",
    "Classification problems represent roughly 80 percent of the machine learning task. Classification aims at predicting the probability of each class given a set of inputs. The label (i.e., the dependent variable) is a discrete value, called a class.\n",
    "\n",
    "- If the label has only two classes, the learning algorithm is a binary classifier.\n",
    "- Multiclass classifier tackles labels with more than two classes.\n",
    "\n",
    "For instance, a typical binary classification problem is to predict the likelihood a customer makes a second purchase. Predict the type of animal displayed on a picture is multiclass classification problem since there are more than two varieties of animal existing.\n",
    "\n",
    "The theoretical part of this tutorial puts primary focus on the binary class. You will learn more about the multiclass output function in a future tutorial.\n",
    "\n",
    "In this tutorial, you will learn\n",
    "\n",
    "+ [What is Linear Classifier?](#what-is-linear-classifier)\n",
    "+ [How Binary classifier works?](#how-binary-classifier-work)\n",
    "+ [How to Measure the performance of Linear Classifier?](#how-to-measure-the-performance-of-linear-classifier)\n",
    "+ [Accuracy](#accuracy)\n",
    "+ [Confusion matrix](#confusion-matrix)\n",
    "+ [Precision and Sensitivity](#precision-and-sensitivity)\n",
    "+ [Linear Classifier with TensorFlow](#linear-classifier-with-tensorflow)\n",
    " - [Step 1) Import the data](#step1-import-the-data)\n",
    " - [Step 2) Data Conversion](#step2-data-conversion)\n",
    " - [Step 3) Train the Classifier](#train-the-classifier)\n",
    " - [Step 4) Improve the model](#improve-the-model)\n",
    " - [Step 5) Hyperparameter:Lasso & Ridge](#hyperparameter-lasso-ridge)\n",
    " \n",
    "## How Binary classifier works?\n",
    "You learned in the previous tutorial that a function is composed of two kind of variables, a dependent variable and a set of features (independent variables). In the linear regression, a dependent variable is a real number without range. The primary objective is to predict its value by minimizing the mean squared error.\n",
    "\n",
    "For a binary task, the label can have had two possible integer values. In most case, it is either [0,1] or [1,2]. For instance, the objective is to predict whether a customer will buy a product or not. The label is defined as follow:\n",
    "\n",
    "- Y = 1 (customer purchases the product)\n",
    "- Y = 0 (customer does not purchase the product)\n",
    "\n",
    "The model uses the features X to classify each customer in the most likely class he belongs to, namely, potential buyer or not.\n",
    "\n",
    "The probability of success is computed with **logistic regression**. The algorithm will compute a probability based on the feature X and predicts a success when this probability is above 50 percent. More formally, the probability is calculated as follow:\n",
    "\n",
    "$P(Y = 1 | x) = \\displaystyle{\\frac{1} {( 1 + exp(-(\\theta^Tx + b)))}}$\n",
    "\n",
    "where 0 is the set of weights, the features and b the bias.\n",
    "\n",
    "The function can be decomposed into two parts:\n",
    "\n",
    "- The linear model\n",
    "- The logistic function\n",
    "\n",
    "### Linear model\n",
    "\n",
    "You are already familiar with the way the weights are computed. Weights are computed using a dot product: Y is a linear function of all the features $x_i$. If the model does not have features, the prediction is equal to the bias, b.\n",
    "\n",
    "The weights indicate the direction of the correlation between the features $x_i$ and the label y. A positive correlation increases the probability of the positive class while a negative correlation leads the probability closer to 0, (i.e., negative class).\n",
    "\n",
    "The linear model returns only real number, which is inconsistent with the probability measure of range [0,1]. The logistic function is required to convert the linear model output to a probability,\n",
    "\n",
    "### Logistic function\n",
    "\n",
    "The logistic function, or sigmoid function, has an S-shape and the output of this function is always between 0 and 1.\n",
    "\n",
    "$\\displaystyle{\\frac{1}{1 + exp(-t)}}$\n",
    "\n",
    "It is easy to substitute the output of the linear regression into the sigmoid function. It results in a new number with a probability between 0 and 1.\n",
    "\n",
    "The classifier can transform the probability into a class\n",
    "\n",
    "- Values between 0 to 0.49 become class 0\n",
    "- Values between 0.5 to 1 become class 1\n",
    "\n",
    "## How to Measure the performance of Linear Classifier?\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "The overall performance of a classifier is measured with the accuracy metric. Accuracy collects all the correct values divided by the total number of observations. For instance, an accuracy value of 80 percent means the model is correct in 80 percent of the cases.\n",
    "\n",
    "You can note a shortcoming with this metric, especially for imbalance class. An imbalance dataset occurs when the number of observations per group is not equal. Let's say; you try to classify a rare event with a logistic function. Imagine the classifier tries to estimate the death of a patient following a disease. In the data, 5 percent of the patients pass away. You can train a classifier to predict the number of death and use the accuracy metric to evaluate the performances. If the classifier predicts 0 death for the entire dataset, it will be correct in 95 percent of the case.\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "A better way to assess the performance of a classifier is to look at the confusion matrix.\n",
    "\n",
    "![](LinearClass.png)\n",
    "\n",
    "The confusion matrix visualizes the accuracy of a classifier by comparing the actual and predicted classes. The binary confusion matrix is composed of squares:\n",
    "\n",
    "- TP: True Positive: Predicted values correctly predicted as actual positive\n",
    "- FP: Predicted values incorrectly predicted an actual positive. i.e., Negative values predicted as positive\n",
    "- FN: False Negative: Positive values predicted as negative\n",
    "- TN: True Negative: Predicted values correctly predicted as actual negative\n",
    "\n",
    "From the confusion matrix, it is easy to compare the actual class and predicted class.\n",
    "\n",
    "### Precision and Sensitivity\n",
    "The confusion matrix provides a good insight into the true positive and false positive. In some case, it is preferable to have a more concise metric.\n",
    "\n",
    "#### Precision\n",
    "\n",
    "The precision metric shows the accuracy of the positive class. It measures how likely the prediction of the positive class is correct.\n",
    "\n",
    "$Precision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "The maximum score is 1 when the classifier perfectly classifies all the positive values. Precision alone is not very helpful because it ignores the negative class. The metric is usually paired with Recall metric. Recall is also called sensitivity or true positive rate.\n",
    "\n",
    "#### Recall or Sensitivity\n",
    "\n",
    "Sensitivity computes the ratio of positive classes correctly detected. This metric gives how good the model is to recognize a positive class.\n",
    "\n",
    "$Recall = \\frac{TP}{TP + FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier with TensorFlow\n",
    "\n",
    "For this tutorial, we will use the census dataset. The purpose is to use the variables in the census dataset to predict the income level. Note that the income is a binary variable\n",
    "\n",
    "- with a value of 1 if the income > 50k\n",
    "- 0 if income < 50k.\n",
    "\n",
    "This variable is your label.\n",
    "\n",
    "This dataset includes eight categorical variables:\n",
    "\n",
    "- workplace\n",
    "- education\n",
    "- marital\n",
    "- occupation\n",
    "- relationship\n",
    "- race\n",
    "- sex\n",
    "- native_country\n",
    "\n",
    "moreover, six continuous variables:\n",
    "\n",
    "- age\n",
    "- fnlwgt\n",
    "- education_num\n",
    "- capital_gain\n",
    "- capital_loss\n",
    "- hours_week\n",
    "\n",
    "Through this example, you will understand how to train a linear classifier with TensorFlow estimator and how to improve the accuracy metric.\n",
    "\n",
    "We will proceed as follow:\n",
    "\n",
    "- Step 1) Import the data\n",
    "- Step 2) Data Conversion\n",
    "- Step 3) Train the classifier\n",
    "- Step 4) Improve the model\n",
    "- Step 5) Hyperparameter:Lasso & Ridge\n",
    "\n",
    "### Step 1) Import the data\n",
    "\n",
    "You first import the libraries used during the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you import the data from the archive of UCI and defines the columns names. You will use the COLUMNS to name the columns in a pandas data frame.\n",
    "\n",
    "**Note** that you will train the classifier using a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data path\n",
    "COLUMNS = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital',\n",
    "          'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
    "          'hours_week', 'native_country', 'label']\n",
    "\n",
    "PATH = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "PATH_test = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data stored online are already divided between a train set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(PATH, skipinitialspace = True, names = COLUMNS, index_col = False)\n",
    "df_test = pd.read_csv(PATH_test, skipinitialspace = True, skiprows = 1, names = COLUMNS, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15) (16281, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train set contains 32,561 observations and the test set 16,281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education_num      int64\n",
      "marital           object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "sex               object\n",
      "capital_gain       int64\n",
      "capital_loss       int64\n",
      "hours_week         int64\n",
      "native_country    object\n",
      "label             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow requires a Boolean value to train the classifier. You need to cast the values from string to integer. The label is store as an object, however, you need to convert it into a numeric value. \n",
    "\n",
    "The code below creates a dictionary with the values to convert and loop over the column item. **Note** that you perform this operation twice, one for the train test, one for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "              marital         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_week native_country  label  \n",
       "0          2174             0          40  United-States  <=50K  \n",
       "1             0             0          13  United-States  <=50K  \n",
       "2             0             0          40  United-States  <=50K  \n",
       "3             0             0          40  United-States  <=50K  \n",
       "4             0             0          40           Cuba  <=50K  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {'<=50K': 0, '>50K': 1}\n",
    "df_train.label = [label[item] for item in df_train.label]\n",
    "label_t = {'<=50K.': 0, '>50K.': 1}\n",
    "df_test.label = [label_t[item] for item in df_test.label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_week</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "      <td>0.427581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
       "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "         hours_week         label  \n",
       "count  32561.000000  32561.000000  \n",
       "mean      40.437456      0.240810  \n",
       "std       12.347429      0.427581  \n",
       "min        1.000000      0.000000  \n",
       "25%       40.000000      0.000000  \n",
       "50%       40.000000      0.000000  \n",
       "75%       45.000000      0.000000  \n",
       "max       99.000000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    24720\n",
      "1     7841\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the train data, there are 24,720 incomes lower than 50k and 7841 above. The ratio is almost the same for the test set. Please refer this tutorial on Facets for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    12435\n",
      "1     3846\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education_num      int64\n",
      "marital           object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "sex               object\n",
      "capital_gain       int64\n",
      "capital_loss       int64\n",
      "hours_week         int64\n",
      "native_country    object\n",
      "label              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Unbalanced label\n",
    "print(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2) Data Conversion\n",
    "\n",
    "A few steps are required before you train a linear classifier with Tensorflow. You need to prepare the features to include in the model. In the benchmark regression, you will use the original data without applying any transformation.\n",
    "\n",
    "The estimator needs to have a list of features to train the model. Hence, the column's data requires to be converted into a tensor.\n",
    "\n",
    "A good practice is to define two lists of features based on their type and then pass them in the feature_columns of the estimator.\n",
    "\n",
    "You will begin by converting continuous features, then define a bucket with the categorical data.\n",
    "\n",
    "The features of the dataset have two formats:\n",
    "\n",
    "- Integer\n",
    "- Object\n",
    "\n",
    "Each feature is listed in the next two variables as per their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features to the bucket\n",
    "# Define the continuous list\n",
    "CONTI_FEATURES = ['age', 'fnlwgt','capital_gain', 'education_num', 'capital_loss', 'hours_week']\n",
    "# Define the categorical list \n",
    "CATE_FEATURES = ['workclass', 'education', 'marital', 'occupation', 'relationship', 'race', 'sex', 'native_country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature_column is equipped with an object numeric_column to help in the transformation of the continuous variables into tensor. In the code below, you convert all the variables from CONTI_FEATURES into a tensor with a numeric value. This is compulsory to construct the model. All the independent variables need to be converted into the proper type of tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [tf.feature_column.numeric_column(k) for k in CONTI_FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to TensorFlow documentation, there are different ways to convert categorical data. If the vocabulary list of a feature is known and does not have plenty of values, it is possible to create the categorical column with categorical_column_with_vocabulary_list. It will assign to all unique vocabulary list an ID.\n",
    "\n",
    "For instance, if a variable status has three distinct values:\n",
    "\n",
    "- Husband\n",
    "- Wife\n",
    "- Single\n",
    "\n",
    "Then three ID will be attributed. For instance, Husband will have the ID 1, Wife the ID 2 and so on.\n",
    "\n",
    "For illustration purpose, you can use this code to convert an object variable to a categorical column in TensorFlow.\n",
    "\n",
    "The feature sex can only have two value: male or female. When we will convert the feature sex, Tensorflow will create 2 new columns, one for male and one for female. If the sex is equal to male, then the new column male will be equal to 1 and female to 0. This example is displayed in the table below:\n",
    "\n",
    "| rows | sex   |after transformation| male| female|\n",
    "|------|-------|--------------------|-----|-------|\n",
    "|   1  | male  | =>                 | 1   | 0     |\n",
    "|   2  | male  | =>                 | 1   | 0     |\n",
    "|   3  | female| =>                 | 0   | 1     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we added Python code to print the encoding. Again, you don't need to understand the code, the purpose is to see the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'relationship', [\n",
    "        'Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried',\n",
    "        'Other-relative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, a faster way to transform the data is to use the method categorical_column_with_hash_bucket. Altering string variables in a sparse matrix will be useful. A sparse matrix is a matrix with mostly zero. The method takes care of everything. You only need to specify the number of buckets and the key column. The number of buckets is the maximum amount of groups that Tensorflow can create. The key column is simply the name of the column to convert.\n",
    "\n",
    "In the code below, you create a loop over all the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [tf.feature_column.categorical_column_with_hash_bucket(k,\n",
    "                                                                              hash_bucket_size = 1000) \n",
    "                       for k in CATE_FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3) Train the Classifier\n",
    "\n",
    "TensorFlow currently provides an estimator for the linear regression and linear classification.\n",
    "\n",
    "- Linear regression: LinearRegressor\n",
    "- Linear classification: LinearClassifier\n",
    "\n",
    "The syntax of the linear classifier is the same as in the tutorial on linear regression except for one argument, n_class. You need to define the feature column, the model directory and, compare with the linear regressor; you have to define the number of class. For a logit regression, it the number of class is equal to 2.\n",
    "\n",
    "The model will compute the weights of the columns contained in continuous_features and categorical_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'ongoing/train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023C8067B8C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(n_classes = 2,\n",
    "                                     model_dir = \"ongoing/train\",\n",
    "                                     feature_columns = categorical_features + continuous_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the classifier is defined, you can create the input function. The method is the same as in the linear regressor tutorial. Here, you use a batch size of 128 and you shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = CONTI_FEATURES + CATE_FEATURES\n",
    "LABEL = 'label'\n",
    "\n",
    "def get_input_fn(data_set, num_epochs = None, n_batch = 128, shuffle = True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = pd.DataFrame({k: data_set[k].values for k in FEATURES}),\n",
    "    y = pd.Series(data_set[LABEL].values),\n",
    "    batch_size = n_batch,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You create a function with the arguments required by the linear estimator, i.e., number of epochs, number of batches and shuffle the dataset or not. Since you use the Pandas method to pass the data into the model, you need to define the X variables as a pandas data frame. Note that you loop over all the data stored in FEATURES.\n",
    "\n",
    "Let's train the model with the object model.train. You use the function previously defined to feed the model with the appropriate values. Note that you set the batch size to 128 and the number of epochs to None. The model will be trained over a thousand steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zhang\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\zhang\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\Users\\zhang\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\zhang\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\zhang\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\zhang\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\zhang\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ongoing/train\\model.ckpt.\n",
      "INFO:tensorflow:loss = 88.722855, step = 0\n",
      "INFO:tensorflow:global_step/sec: 188.878\n",
      "INFO:tensorflow:loss = 52583.64, step = 100 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.298\n",
      "INFO:tensorflow:loss = 25203.816, step = 200 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.424\n",
      "INFO:tensorflow:loss = 54924.312, step = 300 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.744\n",
      "INFO:tensorflow:loss = 68509.31, step = 400 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.657\n",
      "INFO:tensorflow:loss = 9151.754, step = 500 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.414\n",
      "INFO:tensorflow:loss = 34576.06, step = 600 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.27\n",
      "INFO:tensorflow:loss = 36138.97, step = 700 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.488\n",
      "INFO:tensorflow:loss = 13232.442, step = 800 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.407\n",
      "INFO:tensorflow:loss = 57755.734, step = 900 (0.310 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ongoing/train\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5516.2505.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifier at 0x23c8067b708>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn = get_input_fn(df_train,\n",
    "                                   num_epochs = None,\n",
    "                                   n_batch = 128,\n",
    "                                   shuffle = False),\n",
    "           steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the loss decreased subsequently during the last 100 steps, i.e., from 901 to 1000.\n",
    "\n",
    "The final loss after one thousand iterations is 5516. You can estimate your model on the test set and see the performance. To evaluate the performance of your model, you need to use the object evaluate. You feed the model with the test set and set the number of epochs to 1, i.e., the data will go to the model only one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\zhang\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-10-28T19:13:01Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ongoing/train\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2019-10-28-19:13:02\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.6592961, accuracy_baseline = 0.76377374, auc = 0.71584743, auc_precision_recall = 0.60078007, average_loss = 42.312782, global_step = 1000, label/mean = 0.23622628, loss = 5381.988, precision = 0.3885467, prediction/mean = 0.46863696, recall = 0.7709308\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ongoing/train\\model.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6592961,\n",
       " 'accuracy_baseline': 0.76377374,\n",
       " 'auc': 0.71584743,\n",
       " 'auc_precision_recall': 0.60078007,\n",
       " 'average_loss': 42.312782,\n",
       " 'label/mean': 0.23622628,\n",
       " 'loss': 5381.988,\n",
       " 'precision': 0.3885467,\n",
       " 'prediction/mean': 0.46863696,\n",
       " 'recall': 0.7709308,\n",
       " 'global_step': 1000}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(input_fn = get_input_fn(df_test,\n",
    "                                      num_epochs = 1,\n",
    "                                      n_batch = 128,\n",
    "                                      shuffle = False),\n",
    "              steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow returns all the metrics you learnt in the theoretical part. Without surprise, the accuracy is large due to the unbalanced label. Actually, the model performs slightly better than a random guess. Imagine the model predict all household with income lower than 50K, then the model has an accuracy of 70 percent. On a closer analysis, you can see the prediction and recall are quite low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 4) Improve the model\n",
    "\n",
    "Now that you have a benchmark model, you can try to improve it, that is, increase the accuracy. In the previous tutorial, you learned how to improve the prediction power with an interaction term. In this tutorial, you will revisit this idea by adding a polynomial term to the regression.\n",
    "\n",
    "Polynomial regression is instrumental when there is non-linearity in the data. There are two ways to capture non-linearity in the data.\n",
    "\n",
    "- Add polynomial term\n",
    "- Bucketize the continuous variable into a categorical variable\n",
    "\n",
    "#### Polynomial term\n",
    "\n",
    "A polynomial regression is an equation with X variables with different power. A second-degree polynomial regression has two variables, X and X squared. Third degree has three variables, X, X2,and X3\n",
    "\n",
    "Below, we constructed a graph with two variables, X and Y. It is obvious the relationship is not linear. If we add a linear regression, we can see the model is unable to capture the pattern (left picture).\n",
    "\n",
    "Now, look at the left picture from the picture below, we added five-term to the regression (that is $y=x+x^2+x^3+x^4+x^5$. The model now captures way better the pattern. This is the power of polynomial regression.\n",
    "\n",
    "![](LinearClass1.png)\n",
    "\n",
    "Let's go back to our example. Age is not in a linear relationship with income. Early age might have a flat income close to zero because children or young people do not work. Then it increases in working age and decreases during retirement. It is typically an Inversed-U shape. One way to capture this pattern is by adding a power two to the regression.\n",
    "\n",
    "Let's see if it increases the accuracy.\n",
    "\n",
    "You need to add this new feature to the dataset and in the list of continuous feature.\n",
    "\n",
    "You add the new variable in the train and test dataset, so it is more convenient to write a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_var(df_t, df_te, var_name = 'age'):\n",
    "    df_t['new'] = df_t[var_name].pow(2)\n",
    "    df_te['new'] = df_te[var_name].pow(2)\n",
    "    return df_t, df_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function has 3 arguments:\n",
    "\n",
    "- df_t: define the training set\n",
    "- df_te: define the test set\n",
    "- var_name = 'age': Define the variable to transform\n",
    "\n",
    "You can use the object pow(2) to square the variable age. Note that the new variable is named 'new'\n",
    "\n",
    "Now that the function square_var is written, you can create the new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_new, df_test_new = square_var(df_train, df_test, var_name = 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the new dataset has one more feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 16) (16281, 16)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_new.shape, df_test_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The square variable is called new in the dataset. You need to add it to the list of continuous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTI_FEATURES_NEW = CONTI_FEATURES + ['new']\n",
    "continuous_features_new = [tf.feature_column.numeric_column(k) for k in CONTI_FEATURES_NEW]\n",
    "FEATURES = CONTI_FEATURES_NEW + CATE_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that you changed the directory of the Graph. You can't train different models in the same directory. It means, you need to change the path of the argument model_dir. If you don't, TensorFlow will throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'ongoing/train1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023C84DF3F48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.estimator.LinearClassifier(n_classes = 2,\n",
    "                                        model_dir = \"ongoing/train1\",\n",
    "                                       feature_columns = categorical_features + continuous_features_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the classifier is designed with the new dataset, you can train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ongoing/train1\\model.ckpt.\n",
      "INFO:tensorflow:loss = 88.722855, step = 0\n",
      "INFO:tensorflow:global_step/sec: 197.915\n",
      "INFO:tensorflow:loss = 70077.66, step = 100 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.848\n",
      "INFO:tensorflow:loss = 61608.1, step = 200 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.647\n",
      "INFO:tensorflow:loss = 74949.11, step = 300 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.512\n",
      "INFO:tensorflow:loss = 65616.92, step = 400 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.712\n",
      "INFO:tensorflow:loss = 119320.12, step = 500 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.189\n",
      "INFO:tensorflow:loss = 12779.463, step = 600 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.966\n",
      "INFO:tensorflow:loss = 25573.877, step = 700 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.694\n",
      "INFO:tensorflow:loss = 25123.795, step = 800 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.571\n",
      "INFO:tensorflow:loss = 5853.396, step = 900 (0.304 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ongoing/train1\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 28611.793.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifier at 0x23c80531988>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.train(input_fn = get_input_fn(df_train_new,\n",
    "                                     num_epochs = None,\n",
    "                                     n_batch = 128,\n",
    "                                     shuffle = False),\n",
    "             steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-10-28T19:13:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ongoing/train1\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2019-10-28-19:13:13\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.7946072, accuracy_baseline = 0.76377374, auc = 0.61660016, auc_precision_recall = 0.5512627, average_loss = 109.95983, global_step = 1000, label/mean = 0.23622628, loss = 13986.375, precision = 0.65436655, prediction/mean = 0.09982962, recall = 0.27665105\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ongoing/train1\\model.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7946072,\n",
       " 'accuracy_baseline': 0.76377374,\n",
       " 'auc': 0.61660016,\n",
       " 'auc_precision_recall': 0.5512627,\n",
       " 'average_loss': 109.95983,\n",
       " 'label/mean': 0.23622628,\n",
       " 'loss': 13986.375,\n",
       " 'precision': 0.65436655,\n",
       " 'prediction/mean': 0.09982962,\n",
       " 'recall': 0.27665105,\n",
       " 'global_step': 1000}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(input_fn = get_input_fn(df_test_new,\n",
    "                                       num_epochs = 1,\n",
    "                                       n_batch = 128,\n",
    "                                       shuffle = False),\n",
    "               steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The squared variable improved the accuracy. Let's see if you can do better by combining bucketization and interaction term together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketization and interaction\n",
    "\n",
    "As you saw before, a linear classifier is unable to capture the age-income pattern correctly. That is because it learns a single weight for each feature. To make it easier for the classifier, one thing you can do is bucket the feature. Bucketing transforms a numeric feature into several certain ones based on the range it falls into, and each of these new features indicates whether a person's age falls within that range.\n",
    "\n",
    "With these new features, the linear model can capture the relationship by learning different weights for each bucket.\n",
    "\n",
    "In TensorFlow, it is done with bucketized_column. You need to add the range of values in the boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('age')\n",
    "age_buckets = tf.feature_column.bucketized_column(age, boundaries = [ 18, 25, 30, 40,\n",
    "                                                                    45, 50, 55, 60, 65])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You already know age is non-linear with income. Another way to improve the model is through interaction. In the word of TensorFlow, it is **feature crossing**. Feature crossing is a way to create new features that are combinations of existing ones, which can be helpful for a linear classifier that can't model interactions between features.\n",
    "\n",
    "You can break down age with another feature like education. That is is, some groups are likely to have a high income and others low (Think about the Ph.D. student)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_x_occupation = [tf.feature_column.crossed_column(['education',\n",
    "                                                            'occupation'], \n",
    "                                                          hash_bucket_size = 1000)]\n",
    "age_buckets_x_education_x_occupation = [tf.feature_column.crossed_column([age_buckets,\n",
    "                                                                         'education',\n",
    "                                                                        'occupation'], \n",
    "                                                                       hash_bucket_size = 1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a cross feature column, you use crossed_column with the variables to cross in a bracket. The hash_bucket_size indicates the maximum crossing possibilities. To create interaction between variables (*at least one variable needs to be categorical*), you can use tf.feature_column.crossed_column. To use this object, you need to add in square bracket the variable to interact and a second argument, the bucket size. The bucket size is the maximum number of group possible within a variable. Here you set it at 1000 as you do not know the exact number of groups.\n",
    "\n",
    "age_buckets needs to be squared before to add it to the feature columns. You also add the new features to the features columns and prepare the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'ongoing/train3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023C851F4CC8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "base_columns = [age_buckets,]\n",
    "\n",
    "model_imp = tf.estimator.LinearClassifier(n_classes = 2,\n",
    "                                          model_dir = \"ongoing/train3\",\n",
    "                                        feature_columns = categorical_features+\n",
    "                                        base_columns+education_x_occupation+\n",
    "                                        age_buckets_x_education_x_occupation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_imp = ['age','workclass', 'education', 'education_num', 'marital',\n",
    "                'occupation', 'relationship', 'race', 'sex', 'native_country', 'new']\n",
    "\n",
    "def get_input_fn(data_set, num_epochs = None, n_batch = 128, shuffle = True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = pd.DataFrame({k: data_set[k].values for k in FEATURES_imp}),\n",
    "    y = pd.Series(data_set[LABEL].values),\n",
    "    batch_size = n_batch,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are ready to estimate the new model and see if it improves the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ongoing/train3\\model.ckpt.\n",
      "INFO:tensorflow:loss = 88.722855, step = 0\n",
      "INFO:tensorflow:global_step/sec: 195.958\n",
      "INFO:tensorflow:loss = 50.449852, step = 100 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.493\n",
      "INFO:tensorflow:loss = 56.948494, step = 200 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.765\n",
      "INFO:tensorflow:loss = 46.765556, step = 300 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.695\n",
      "INFO:tensorflow:loss = 37.31914, step = 400 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.066\n",
      "INFO:tensorflow:loss = 55.965073, step = 500 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.425\n",
      "INFO:tensorflow:loss = 33.835857, step = 600 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.772\n",
      "INFO:tensorflow:loss = 37.990814, step = 700 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.141\n",
      "INFO:tensorflow:loss = 58.72903, step = 800 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.36\n",
      "INFO:tensorflow:loss = 44.388985, step = 900 (0.269 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ongoing/train3\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 44.21843.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifier at 0x23c851f8808>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imp.train(input_fn = get_input_fn(df_train_new,\n",
    "                                       num_epochs = None,\n",
    "                                       n_batch = 128,\n",
    "                                       shuffle = False),\n",
    "               steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-10-28T19:13:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ongoing/train3\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2019-10-28-19:13:22\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.8356366, accuracy_baseline = 0.76377374, auc = 0.88404787, auc_precision_recall = 0.6964099, average_loss = 0.3510878, global_step = 1000, label/mean = 0.23622628, loss = 44.656723, precision = 0.6969697, prediction/mean = 0.23178273, recall = 0.53822154\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ongoing/train3\\model.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8356366,\n",
       " 'accuracy_baseline': 0.76377374,\n",
       " 'auc': 0.88404787,\n",
       " 'auc_precision_recall': 0.6964099,\n",
       " 'average_loss': 0.3510878,\n",
       " 'label/mean': 0.23622628,\n",
       " 'loss': 44.656723,\n",
       " 'precision': 0.6969697,\n",
       " 'prediction/mean': 0.23178273,\n",
       " 'recall': 0.53822154,\n",
       " 'global_step': 1000}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imp.evaluate(input_fn = get_input_fn(df_test_new,\n",
    "                                          num_epochs = 1,\n",
    "                                          n_batch = 128,\n",
    "                                          shuffle = False),\n",
    "                  steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new accuracy level is 83.56 percent. It is 6.5 percent higher than the previous model.\n",
    "\n",
    "Finally, you can add a regularization term to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5) Hyperparameter:Lasso & Ridge\n",
    "\n",
    "Your model can suffer from **overfitting** or **underfitting**.\n",
    "\n",
    "- Overfitting: The model is unable to generalize the prediction to new data\n",
    "- Underfitting: The model is unable to capture the pattern of the data. i.e., linear regression when the data is non-linear\n",
    "\n",
    "When a model has lots of parameters and a relatively low amount of data, it leads to poor predictions. Imagine, one group only have three observations; the model will compute a weight for this group. The weight is used to make a prediction; if the observations of the test set for this particular group is entirely different from the training set, then the model will make a wrong prediction. During the evaluation with the training set, the accuracy is good, but not good with the test set because the weights computed is not the true one to generalize the pattern. In this case, it does not make a reasonable prediction on unseen data.\n",
    "\n",
    "To prevent overfitting, **regularization** gives you the possibilities to control for such complexity and make it more generalizable. There are two regularization techniques:\n",
    "\n",
    "- L1: Lasso\n",
    "- L2: Ridge\n",
    "\n",
    "In TensorFlow, you can add these two hyperparameters in the optimizer. For instance, the higher the hyperparameter L2, the weight tends to be very low and close to zero. The fitted line will be very flat, while an L2 close to zero implies the weights are close to the regular linear regression.\n",
    "\n",
    "You can try by yourself the different value of the hyperparameters and see if you can increase the accuracy level.\n",
    "\n",
    "**Note** that if you change the hyperparameter, you need to delete the folder ongoing/train4 otherwise the model will start with the previously trained model.\n",
    "\n",
    "Let's see how is the accuracy with the hypeparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'ongoing/train4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023C81FD7448>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_regu = tf.estimator.LinearClassifier(n_classes = 2,\n",
    "                                          model_dir = \"ongoing/train4\",\n",
    "                                          feature_columns = categorical_features+\n",
    "                                          base_columns+education_x_occupation+\n",
    "                                          age_buckets_x_education_x_occupation,\n",
    "                                          optimizer = tf.train.FtrlOptimizer(\n",
    "                                          learning_rate = 0.1,\n",
    "                                          l1_regularization_strength = 0.9,\n",
    "                                          l2_regularization_strength = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ongoing/train4\\model.ckpt.\n",
      "INFO:tensorflow:loss = 88.722855, step = 0\n",
      "INFO:tensorflow:global_step/sec: 179.369\n",
      "INFO:tensorflow:loss = 50.41912, step = 100 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.726\n",
      "INFO:tensorflow:loss = 55.473183, step = 200 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.384\n",
      "INFO:tensorflow:loss = 47.190437, step = 300 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.483\n",
      "INFO:tensorflow:loss = 38.447006, step = 400 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.421\n",
      "INFO:tensorflow:loss = 56.87366, step = 500 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.937\n",
      "INFO:tensorflow:loss = 34.191418, step = 600 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.542\n",
      "INFO:tensorflow:loss = 37.974693, step = 700 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.729\n",
      "INFO:tensorflow:loss = 59.962883, step = 800 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.458\n",
      "INFO:tensorflow:loss = 46.485252, step = 900 (0.279 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ongoing/train4\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 43.842594.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifier at 0x23c81fd7988>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regu.train(input_fn = get_input_fn(df_train_new,\n",
    "                                        num_epochs = None,\n",
    "                                        n_batch = 128,\n",
    "                                        shuffle = False),\n",
    "                steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-10-28T19:13:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ongoing/train4\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2019-10-28-19:13:32\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.83668077, accuracy_baseline = 0.76377374, auc = 0.8867973, auc_precision_recall = 0.7010116, average_loss = 0.3472121, global_step = 1000, label/mean = 0.23622628, loss = 44.163754, precision = 0.69869435, prediction/mean = 0.23615354, recall = 0.5426417\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ongoing/train4\\model.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.83668077,\n",
       " 'accuracy_baseline': 0.76377374,\n",
       " 'auc': 0.8867973,\n",
       " 'auc_precision_recall': 0.7010116,\n",
       " 'average_loss': 0.3472121,\n",
       " 'label/mean': 0.23622628,\n",
       " 'loss': 44.163754,\n",
       " 'precision': 0.69869435,\n",
       " 'prediction/mean': 0.23615354,\n",
       " 'recall': 0.5426417,\n",
       " 'global_step': 1000}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regu.evaluate(input_fn = get_input_fn(df_test_new,\n",
    "                                           num_epochs = 1,\n",
    "                                           n_batch = 128,\n",
    "                                           shuffle = False),\n",
    "                   steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this hyperparameter, you slightly increase the accuracy metrics. In the next tutorial, you will learn how to improve a linear classifier using a kernel method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "To train a model, you need to:\n",
    "\n",
    "- Define the features: Independent variables: X\n",
    "- Define the label: Dependent variable: y\n",
    "- Construct a train/test set\n",
    "- Define the initial weight\n",
    "- Define the loss function: MSE\n",
    "- Optimize the model: Gradient descent\n",
    "- Define:\n",
    " - Learning rate\n",
    " - Number of epoch\n",
    " - Batch size\n",
    " - Number of class\n",
    "\n",
    "In this tutorial, you learned how to use the high-level API for a linear regression classifier. You need to define:\n",
    "\n",
    "1. Feature columns. If continuous: tf.feature_column.numeric_column(). You can populate a list with python list comprehension\n",
    "2. The estimator: tf.estimator.LinearClassifier(feature_columns, model_dir, n_classes = 2)\n",
    "3. A function to import the data, the batch size and epoch: input_fn()\n",
    "\n",
    "After that, you are ready to train, evaluate and make a prediction with train(), evaluate() and predict()\n",
    "\n",
    "To improve the performance of the model, you can:\n",
    "\n",
    "- Use polynomial regression\n",
    "- Interaction term: tf.feature_column.crossed_column\n",
    "- Add regularization parameter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
